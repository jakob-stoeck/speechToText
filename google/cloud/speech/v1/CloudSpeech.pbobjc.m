// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: google/cloud/speech/v1/cloud_speech.proto

// This CPP symbol can be defined to use imports that match up to the framework
// imports needed when using CocoaPods.
#if !defined(GPB_USE_PROTOBUF_FRAMEWORK_IMPORTS)
 #define GPB_USE_PROTOBUF_FRAMEWORK_IMPORTS 0
#endif

#if GPB_USE_PROTOBUF_FRAMEWORK_IMPORTS
 #import <Protobuf/GPBProtocolBuffers_RuntimeSupport.h>
#else
 #import "GPBProtocolBuffers_RuntimeSupport.h"
#endif

#import <stdatomic.h>

#import <googleapis/CloudSpeech.pbobjc.h>
#import <googleapis/Annotations.pbobjc.h>
#import <googleapis/Operations.pbobjc.h>
#import <googleapis/Status.pbobjc.h>
// @@protoc_insertion_point(imports)

#pragma clang diagnostic push
#pragma clang diagnostic ignored "-Wdeprecated-declarations"
#pragma clang diagnostic ignored "-Wdirect-ivar-access"

#pragma mark - CloudSpeechRoot

@implementation CloudSpeechRoot

+ (GPBExtensionRegistry*)extensionRegistry {
  // This is called by +initialize so there is no need to worry
  // about thread safety and initialization of registry.
  static GPBExtensionRegistry* registry = nil;
  if (!registry) {
    GPB_DEBUG_CHECK_RUNTIME_VERSIONS();
    registry = [[GPBExtensionRegistry alloc] init];
    // Merge in the imports (direct or indirect) that defined extensions.
    [registry addExtensions:[AnnotationsRoot extensionRegistry]];
  }
  return registry;
}

@end

#pragma mark - CloudSpeechRoot_FileDescriptor

static GPBFileDescriptor *CloudSpeechRoot_FileDescriptor(void) {
  // This is called by +initialize so there is no need to worry
  // about thread safety of the singleton.
  static GPBFileDescriptor *descriptor = NULL;
  if (!descriptor) {
    GPB_DEBUG_CHECK_RUNTIME_VERSIONS();
    descriptor = [[GPBFileDescriptor alloc] initWithPackage:@"google.cloud.speech.v1"
                                                     syntax:GPBFileSyntaxProto3];
  }
  return descriptor;
}

#pragma mark - RecognizeRequest

@implementation RecognizeRequest

@dynamic hasConfig, config;
@dynamic hasAudio, audio;

typedef struct RecognizeRequest__storage_ {
  uint32_t _has_storage_[1];
  RecognitionConfig *config;
  RecognitionAudio *audio;
} RecognizeRequest__storage_;

// This method is threadsafe because it is initially called
// in +initialize for each subclass.
+ (GPBDescriptor *)descriptor {
  static GPBDescriptor *descriptor = nil;
  if (!descriptor) {
    static GPBMessageFieldDescription fields[] = {
      {
        .name = "config",
        .dataTypeSpecific.className = GPBStringifySymbol(RecognitionConfig),
        .number = RecognizeRequest_FieldNumber_Config,
        .hasIndex = 0,
        .offset = (uint32_t)offsetof(RecognizeRequest__storage_, config),
        .flags = GPBFieldOptional,
        .dataType = GPBDataTypeMessage,
      },
      {
        .name = "audio",
        .dataTypeSpecific.className = GPBStringifySymbol(RecognitionAudio),
        .number = RecognizeRequest_FieldNumber_Audio,
        .hasIndex = 1,
        .offset = (uint32_t)offsetof(RecognizeRequest__storage_, audio),
        .flags = GPBFieldOptional,
        .dataType = GPBDataTypeMessage,
      },
    };
    GPBDescriptor *localDescriptor =
        [GPBDescriptor allocDescriptorForClass:[RecognizeRequest class]
                                     rootClass:[CloudSpeechRoot class]
                                          file:CloudSpeechRoot_FileDescriptor()
                                        fields:fields
                                    fieldCount:(uint32_t)(sizeof(fields) / sizeof(GPBMessageFieldDescription))
                                   storageSize:sizeof(RecognizeRequest__storage_)
                                         flags:GPBDescriptorInitializationFlag_None];
    NSAssert(descriptor == nil, @"Startup recursed!");
    descriptor = localDescriptor;
  }
  return descriptor;
}

@end

#pragma mark - LongRunningRecognizeRequest

@implementation LongRunningRecognizeRequest

@dynamic hasConfig, config;
@dynamic hasAudio, audio;

typedef struct LongRunningRecognizeRequest__storage_ {
  uint32_t _has_storage_[1];
  RecognitionConfig *config;
  RecognitionAudio *audio;
} LongRunningRecognizeRequest__storage_;

// This method is threadsafe because it is initially called
// in +initialize for each subclass.
+ (GPBDescriptor *)descriptor {
  static GPBDescriptor *descriptor = nil;
  if (!descriptor) {
    static GPBMessageFieldDescription fields[] = {
      {
        .name = "config",
        .dataTypeSpecific.className = GPBStringifySymbol(RecognitionConfig),
        .number = LongRunningRecognizeRequest_FieldNumber_Config,
        .hasIndex = 0,
        .offset = (uint32_t)offsetof(LongRunningRecognizeRequest__storage_, config),
        .flags = GPBFieldOptional,
        .dataType = GPBDataTypeMessage,
      },
      {
        .name = "audio",
        .dataTypeSpecific.className = GPBStringifySymbol(RecognitionAudio),
        .number = LongRunningRecognizeRequest_FieldNumber_Audio,
        .hasIndex = 1,
        .offset = (uint32_t)offsetof(LongRunningRecognizeRequest__storage_, audio),
        .flags = GPBFieldOptional,
        .dataType = GPBDataTypeMessage,
      },
    };
    GPBDescriptor *localDescriptor =
        [GPBDescriptor allocDescriptorForClass:[LongRunningRecognizeRequest class]
                                     rootClass:[CloudSpeechRoot class]
                                          file:CloudSpeechRoot_FileDescriptor()
                                        fields:fields
                                    fieldCount:(uint32_t)(sizeof(fields) / sizeof(GPBMessageFieldDescription))
                                   storageSize:sizeof(LongRunningRecognizeRequest__storage_)
                                         flags:GPBDescriptorInitializationFlag_None];
    NSAssert(descriptor == nil, @"Startup recursed!");
    descriptor = localDescriptor;
  }
  return descriptor;
}

@end

#pragma mark - StreamingRecognizeRequest

@implementation StreamingRecognizeRequest

@dynamic streamingRequestOneOfCase;
@dynamic streamingConfig;
@dynamic audioContent;

typedef struct StreamingRecognizeRequest__storage_ {
  uint32_t _has_storage_[2];
  StreamingRecognitionConfig *streamingConfig;
  NSData *audioContent;
} StreamingRecognizeRequest__storage_;

// This method is threadsafe because it is initially called
// in +initialize for each subclass.
+ (GPBDescriptor *)descriptor {
  static GPBDescriptor *descriptor = nil;
  if (!descriptor) {
    static GPBMessageFieldDescription fields[] = {
      {
        .name = "streamingConfig",
        .dataTypeSpecific.className = GPBStringifySymbol(StreamingRecognitionConfig),
        .number = StreamingRecognizeRequest_FieldNumber_StreamingConfig,
        .hasIndex = -1,
        .offset = (uint32_t)offsetof(StreamingRecognizeRequest__storage_, streamingConfig),
        .flags = GPBFieldOptional,
        .dataType = GPBDataTypeMessage,
      },
      {
        .name = "audioContent",
        .dataTypeSpecific.className = NULL,
        .number = StreamingRecognizeRequest_FieldNumber_AudioContent,
        .hasIndex = -1,
        .offset = (uint32_t)offsetof(StreamingRecognizeRequest__storage_, audioContent),
        .flags = GPBFieldOptional,
        .dataType = GPBDataTypeBytes,
      },
    };
    GPBDescriptor *localDescriptor =
        [GPBDescriptor allocDescriptorForClass:[StreamingRecognizeRequest class]
                                     rootClass:[CloudSpeechRoot class]
                                          file:CloudSpeechRoot_FileDescriptor()
                                        fields:fields
                                    fieldCount:(uint32_t)(sizeof(fields) / sizeof(GPBMessageFieldDescription))
                                   storageSize:sizeof(StreamingRecognizeRequest__storage_)
                                         flags:GPBDescriptorInitializationFlag_None];
    static const char *oneofs[] = {
      "streamingRequest",
    };
    [localDescriptor setupOneofs:oneofs
                           count:(uint32_t)(sizeof(oneofs) / sizeof(char*))
                   firstHasIndex:-1];
    NSAssert(descriptor == nil, @"Startup recursed!");
    descriptor = localDescriptor;
  }
  return descriptor;
}

@end

void StreamingRecognizeRequest_ClearStreamingRequestOneOfCase(StreamingRecognizeRequest *message) {
  GPBDescriptor *descriptor = [message descriptor];
  GPBOneofDescriptor *oneof = [descriptor.oneofs objectAtIndex:0];
  GPBMaybeClearOneof(message, oneof, -1, 0);
}
#pragma mark - StreamingRecognitionConfig

@implementation StreamingRecognitionConfig

@dynamic hasConfig, config;
@dynamic singleUtterance;
@dynamic interimResults;

typedef struct StreamingRecognitionConfig__storage_ {
  uint32_t _has_storage_[1];
  RecognitionConfig *config;
} StreamingRecognitionConfig__storage_;

// This method is threadsafe because it is initially called
// in +initialize for each subclass.
+ (GPBDescriptor *)descriptor {
  static GPBDescriptor *descriptor = nil;
  if (!descriptor) {
    static GPBMessageFieldDescription fields[] = {
      {
        .name = "config",
        .dataTypeSpecific.className = GPBStringifySymbol(RecognitionConfig),
        .number = StreamingRecognitionConfig_FieldNumber_Config,
        .hasIndex = 0,
        .offset = (uint32_t)offsetof(StreamingRecognitionConfig__storage_, config),
        .flags = GPBFieldOptional,
        .dataType = GPBDataTypeMessage,
      },
      {
        .name = "singleUtterance",
        .dataTypeSpecific.className = NULL,
        .number = StreamingRecognitionConfig_FieldNumber_SingleUtterance,
        .hasIndex = 1,
        .offset = 2,  // Stored in _has_storage_ to save space.
        .flags = GPBFieldOptional,
        .dataType = GPBDataTypeBool,
      },
      {
        .name = "interimResults",
        .dataTypeSpecific.className = NULL,
        .number = StreamingRecognitionConfig_FieldNumber_InterimResults,
        .hasIndex = 3,
        .offset = 4,  // Stored in _has_storage_ to save space.
        .flags = GPBFieldOptional,
        .dataType = GPBDataTypeBool,
      },
    };
    GPBDescriptor *localDescriptor =
        [GPBDescriptor allocDescriptorForClass:[StreamingRecognitionConfig class]
                                     rootClass:[CloudSpeechRoot class]
                                          file:CloudSpeechRoot_FileDescriptor()
                                        fields:fields
                                    fieldCount:(uint32_t)(sizeof(fields) / sizeof(GPBMessageFieldDescription))
                                   storageSize:sizeof(StreamingRecognitionConfig__storage_)
                                         flags:GPBDescriptorInitializationFlag_None];
    NSAssert(descriptor == nil, @"Startup recursed!");
    descriptor = localDescriptor;
  }
  return descriptor;
}

@end

#pragma mark - RecognitionConfig

@implementation RecognitionConfig

@dynamic encoding;
@dynamic sampleRateHertz;
@dynamic languageCode;
@dynamic maxAlternatives;
@dynamic profanityFilter;
@dynamic speechContextsArray, speechContextsArray_Count;
@dynamic enableWordTimeOffsets;

typedef struct RecognitionConfig__storage_ {
  uint32_t _has_storage_[1];
  RecognitionConfig_AudioEncoding encoding;
  int32_t sampleRateHertz;
  int32_t maxAlternatives;
  NSString *languageCode;
  NSMutableArray *speechContextsArray;
} RecognitionConfig__storage_;

// This method is threadsafe because it is initially called
// in +initialize for each subclass.
+ (GPBDescriptor *)descriptor {
  static GPBDescriptor *descriptor = nil;
  if (!descriptor) {
    static GPBMessageFieldDescription fields[] = {
      {
        .name = "encoding",
        .dataTypeSpecific.enumDescFunc = RecognitionConfig_AudioEncoding_EnumDescriptor,
        .number = RecognitionConfig_FieldNumber_Encoding,
        .hasIndex = 0,
        .offset = (uint32_t)offsetof(RecognitionConfig__storage_, encoding),
        .flags = (GPBFieldFlags)(GPBFieldOptional | GPBFieldHasEnumDescriptor),
        .dataType = GPBDataTypeEnum,
      },
      {
        .name = "sampleRateHertz",
        .dataTypeSpecific.className = NULL,
        .number = RecognitionConfig_FieldNumber_SampleRateHertz,
        .hasIndex = 1,
        .offset = (uint32_t)offsetof(RecognitionConfig__storage_, sampleRateHertz),
        .flags = GPBFieldOptional,
        .dataType = GPBDataTypeInt32,
      },
      {
        .name = "languageCode",
        .dataTypeSpecific.className = NULL,
        .number = RecognitionConfig_FieldNumber_LanguageCode,
        .hasIndex = 2,
        .offset = (uint32_t)offsetof(RecognitionConfig__storage_, languageCode),
        .flags = GPBFieldOptional,
        .dataType = GPBDataTypeString,
      },
      {
        .name = "maxAlternatives",
        .dataTypeSpecific.className = NULL,
        .number = RecognitionConfig_FieldNumber_MaxAlternatives,
        .hasIndex = 3,
        .offset = (uint32_t)offsetof(RecognitionConfig__storage_, maxAlternatives),
        .flags = GPBFieldOptional,
        .dataType = GPBDataTypeInt32,
      },
      {
        .name = "profanityFilter",
        .dataTypeSpecific.className = NULL,
        .number = RecognitionConfig_FieldNumber_ProfanityFilter,
        .hasIndex = 4,
        .offset = 5,  // Stored in _has_storage_ to save space.
        .flags = GPBFieldOptional,
        .dataType = GPBDataTypeBool,
      },
      {
        .name = "speechContextsArray",
        .dataTypeSpecific.className = GPBStringifySymbol(SpeechContext),
        .number = RecognitionConfig_FieldNumber_SpeechContextsArray,
        .hasIndex = GPBNoHasBit,
        .offset = (uint32_t)offsetof(RecognitionConfig__storage_, speechContextsArray),
        .flags = GPBFieldRepeated,
        .dataType = GPBDataTypeMessage,
      },
      {
        .name = "enableWordTimeOffsets",
        .dataTypeSpecific.className = NULL,
        .number = RecognitionConfig_FieldNumber_EnableWordTimeOffsets,
        .hasIndex = 6,
        .offset = 7,  // Stored in _has_storage_ to save space.
        .flags = GPBFieldOptional,
        .dataType = GPBDataTypeBool,
      },
    };
    GPBDescriptor *localDescriptor =
        [GPBDescriptor allocDescriptorForClass:[RecognitionConfig class]
                                     rootClass:[CloudSpeechRoot class]
                                          file:CloudSpeechRoot_FileDescriptor()
                                        fields:fields
                                    fieldCount:(uint32_t)(sizeof(fields) / sizeof(GPBMessageFieldDescription))
                                   storageSize:sizeof(RecognitionConfig__storage_)
                                         flags:GPBDescriptorInitializationFlag_None];
    NSAssert(descriptor == nil, @"Startup recursed!");
    descriptor = localDescriptor;
  }
  return descriptor;
}

@end

int32_t RecognitionConfig_Encoding_RawValue(RecognitionConfig *message) {
  GPBDescriptor *descriptor = [RecognitionConfig descriptor];
  GPBFieldDescriptor *field = [descriptor fieldWithNumber:RecognitionConfig_FieldNumber_Encoding];
  return GPBGetMessageInt32Field(message, field);
}

void SetRecognitionConfig_Encoding_RawValue(RecognitionConfig *message, int32_t value) {
  GPBDescriptor *descriptor = [RecognitionConfig descriptor];
  GPBFieldDescriptor *field = [descriptor fieldWithNumber:RecognitionConfig_FieldNumber_Encoding];
  GPBSetInt32IvarWithFieldInternal(message, field, value, descriptor.file.syntax);
}

#pragma mark - Enum RecognitionConfig_AudioEncoding

GPBEnumDescriptor *RecognitionConfig_AudioEncoding_EnumDescriptor(void) {
  static _Atomic(GPBEnumDescriptor*) descriptor = nil;
  if (!descriptor) {
    static const char *valueNames =
        "EncodingUnspecified\000Linear16\000Flac\000Mulaw\000"
        "Amr\000AmrWb\000OggOpus\000SpeexWithHeaderByte\000";
    static const int32_t values[] = {
        RecognitionConfig_AudioEncoding_EncodingUnspecified,
        RecognitionConfig_AudioEncoding_Linear16,
        RecognitionConfig_AudioEncoding_Flac,
        RecognitionConfig_AudioEncoding_Mulaw,
        RecognitionConfig_AudioEncoding_Amr,
        RecognitionConfig_AudioEncoding_AmrWb,
        RecognitionConfig_AudioEncoding_OggOpus,
        RecognitionConfig_AudioEncoding_SpeexWithHeaderByte,
    };
    GPBEnumDescriptor *worker =
        [GPBEnumDescriptor allocDescriptorForName:GPBNSStringifySymbol(RecognitionConfig_AudioEncoding)
                                       valueNames:valueNames
                                           values:values
                                            count:(uint32_t)(sizeof(values) / sizeof(int32_t))
                                     enumVerifier:RecognitionConfig_AudioEncoding_IsValidValue];
    GPBEnumDescriptor *expected = nil;
    if (!atomic_compare_exchange_strong(&descriptor, &expected, worker)) {
      [worker release];
    }
  }
  return descriptor;
}

BOOL RecognitionConfig_AudioEncoding_IsValidValue(int32_t value__) {
  switch (value__) {
    case RecognitionConfig_AudioEncoding_EncodingUnspecified:
    case RecognitionConfig_AudioEncoding_Linear16:
    case RecognitionConfig_AudioEncoding_Flac:
    case RecognitionConfig_AudioEncoding_Mulaw:
    case RecognitionConfig_AudioEncoding_Amr:
    case RecognitionConfig_AudioEncoding_AmrWb:
    case RecognitionConfig_AudioEncoding_OggOpus:
    case RecognitionConfig_AudioEncoding_SpeexWithHeaderByte:
      return YES;
    default:
      return NO;
  }
}

#pragma mark - SpeechContext

@implementation SpeechContext

@dynamic phrasesArray, phrasesArray_Count;

typedef struct SpeechContext__storage_ {
  uint32_t _has_storage_[1];
  NSMutableArray *phrasesArray;
} SpeechContext__storage_;

// This method is threadsafe because it is initially called
// in +initialize for each subclass.
+ (GPBDescriptor *)descriptor {
  static GPBDescriptor *descriptor = nil;
  if (!descriptor) {
    static GPBMessageFieldDescription fields[] = {
      {
        .name = "phrasesArray",
        .dataTypeSpecific.className = NULL,
        .number = SpeechContext_FieldNumber_PhrasesArray,
        .hasIndex = GPBNoHasBit,
        .offset = (uint32_t)offsetof(SpeechContext__storage_, phrasesArray),
        .flags = GPBFieldRepeated,
        .dataType = GPBDataTypeString,
      },
    };
    GPBDescriptor *localDescriptor =
        [GPBDescriptor allocDescriptorForClass:[SpeechContext class]
                                     rootClass:[CloudSpeechRoot class]
                                          file:CloudSpeechRoot_FileDescriptor()
                                        fields:fields
                                    fieldCount:(uint32_t)(sizeof(fields) / sizeof(GPBMessageFieldDescription))
                                   storageSize:sizeof(SpeechContext__storage_)
                                         flags:GPBDescriptorInitializationFlag_None];
    NSAssert(descriptor == nil, @"Startup recursed!");
    descriptor = localDescriptor;
  }
  return descriptor;
}

@end

#pragma mark - RecognitionAudio

@implementation RecognitionAudio

@dynamic audioSourceOneOfCase;
@dynamic content;
@dynamic uri;

typedef struct RecognitionAudio__storage_ {
  uint32_t _has_storage_[2];
  NSData *content;
  NSString *uri;
} RecognitionAudio__storage_;

// This method is threadsafe because it is initially called
// in +initialize for each subclass.
+ (GPBDescriptor *)descriptor {
  static GPBDescriptor *descriptor = nil;
  if (!descriptor) {
    static GPBMessageFieldDescription fields[] = {
      {
        .name = "content",
        .dataTypeSpecific.className = NULL,
        .number = RecognitionAudio_FieldNumber_Content,
        .hasIndex = -1,
        .offset = (uint32_t)offsetof(RecognitionAudio__storage_, content),
        .flags = GPBFieldOptional,
        .dataType = GPBDataTypeBytes,
      },
      {
        .name = "uri",
        .dataTypeSpecific.className = NULL,
        .number = RecognitionAudio_FieldNumber_Uri,
        .hasIndex = -1,
        .offset = (uint32_t)offsetof(RecognitionAudio__storage_, uri),
        .flags = GPBFieldOptional,
        .dataType = GPBDataTypeString,
      },
    };
    GPBDescriptor *localDescriptor =
        [GPBDescriptor allocDescriptorForClass:[RecognitionAudio class]
                                     rootClass:[CloudSpeechRoot class]
                                          file:CloudSpeechRoot_FileDescriptor()
                                        fields:fields
                                    fieldCount:(uint32_t)(sizeof(fields) / sizeof(GPBMessageFieldDescription))
                                   storageSize:sizeof(RecognitionAudio__storage_)
                                         flags:GPBDescriptorInitializationFlag_None];
    static const char *oneofs[] = {
      "audioSource",
    };
    [localDescriptor setupOneofs:oneofs
                           count:(uint32_t)(sizeof(oneofs) / sizeof(char*))
                   firstHasIndex:-1];
    NSAssert(descriptor == nil, @"Startup recursed!");
    descriptor = localDescriptor;
  }
  return descriptor;
}

@end

void RecognitionAudio_ClearAudioSourceOneOfCase(RecognitionAudio *message) {
  GPBDescriptor *descriptor = [message descriptor];
  GPBOneofDescriptor *oneof = [descriptor.oneofs objectAtIndex:0];
  GPBMaybeClearOneof(message, oneof, -1, 0);
}
#pragma mark - RecognizeResponse

@implementation RecognizeResponse

@dynamic resultsArray, resultsArray_Count;

typedef struct RecognizeResponse__storage_ {
  uint32_t _has_storage_[1];
  NSMutableArray *resultsArray;
} RecognizeResponse__storage_;

// This method is threadsafe because it is initially called
// in +initialize for each subclass.
+ (GPBDescriptor *)descriptor {
  static GPBDescriptor *descriptor = nil;
  if (!descriptor) {
    static GPBMessageFieldDescription fields[] = {
      {
        .name = "resultsArray",
        .dataTypeSpecific.className = GPBStringifySymbol(SpeechRecognitionResult),
        .number = RecognizeResponse_FieldNumber_ResultsArray,
        .hasIndex = GPBNoHasBit,
        .offset = (uint32_t)offsetof(RecognizeResponse__storage_, resultsArray),
        .flags = GPBFieldRepeated,
        .dataType = GPBDataTypeMessage,
      },
    };
    GPBDescriptor *localDescriptor =
        [GPBDescriptor allocDescriptorForClass:[RecognizeResponse class]
                                     rootClass:[CloudSpeechRoot class]
                                          file:CloudSpeechRoot_FileDescriptor()
                                        fields:fields
                                    fieldCount:(uint32_t)(sizeof(fields) / sizeof(GPBMessageFieldDescription))
                                   storageSize:sizeof(RecognizeResponse__storage_)
                                         flags:GPBDescriptorInitializationFlag_None];
    NSAssert(descriptor == nil, @"Startup recursed!");
    descriptor = localDescriptor;
  }
  return descriptor;
}

@end

#pragma mark - LongRunningRecognizeResponse

@implementation LongRunningRecognizeResponse

@dynamic resultsArray, resultsArray_Count;

typedef struct LongRunningRecognizeResponse__storage_ {
  uint32_t _has_storage_[1];
  NSMutableArray *resultsArray;
} LongRunningRecognizeResponse__storage_;

// This method is threadsafe because it is initially called
// in +initialize for each subclass.
+ (GPBDescriptor *)descriptor {
  static GPBDescriptor *descriptor = nil;
  if (!descriptor) {
    static GPBMessageFieldDescription fields[] = {
      {
        .name = "resultsArray",
        .dataTypeSpecific.className = GPBStringifySymbol(SpeechRecognitionResult),
        .number = LongRunningRecognizeResponse_FieldNumber_ResultsArray,
        .hasIndex = GPBNoHasBit,
        .offset = (uint32_t)offsetof(LongRunningRecognizeResponse__storage_, resultsArray),
        .flags = GPBFieldRepeated,
        .dataType = GPBDataTypeMessage,
      },
    };
    GPBDescriptor *localDescriptor =
        [GPBDescriptor allocDescriptorForClass:[LongRunningRecognizeResponse class]
                                     rootClass:[CloudSpeechRoot class]
                                          file:CloudSpeechRoot_FileDescriptor()
                                        fields:fields
                                    fieldCount:(uint32_t)(sizeof(fields) / sizeof(GPBMessageFieldDescription))
                                   storageSize:sizeof(LongRunningRecognizeResponse__storage_)
                                         flags:GPBDescriptorInitializationFlag_None];
    NSAssert(descriptor == nil, @"Startup recursed!");
    descriptor = localDescriptor;
  }
  return descriptor;
}

@end

#pragma mark - LongRunningRecognizeMetadata

@implementation LongRunningRecognizeMetadata

@dynamic progressPercent;
@dynamic hasStartTime, startTime;
@dynamic hasLastUpdateTime, lastUpdateTime;

typedef struct LongRunningRecognizeMetadata__storage_ {
  uint32_t _has_storage_[1];
  int32_t progressPercent;
  GPBTimestamp *startTime;
  GPBTimestamp *lastUpdateTime;
} LongRunningRecognizeMetadata__storage_;

// This method is threadsafe because it is initially called
// in +initialize for each subclass.
+ (GPBDescriptor *)descriptor {
  static GPBDescriptor *descriptor = nil;
  if (!descriptor) {
    static GPBMessageFieldDescription fields[] = {
      {
        .name = "progressPercent",
        .dataTypeSpecific.className = NULL,
        .number = LongRunningRecognizeMetadata_FieldNumber_ProgressPercent,
        .hasIndex = 0,
        .offset = (uint32_t)offsetof(LongRunningRecognizeMetadata__storage_, progressPercent),
        .flags = GPBFieldOptional,
        .dataType = GPBDataTypeInt32,
      },
      {
        .name = "startTime",
        .dataTypeSpecific.className = GPBStringifySymbol(GPBTimestamp),
        .number = LongRunningRecognizeMetadata_FieldNumber_StartTime,
        .hasIndex = 1,
        .offset = (uint32_t)offsetof(LongRunningRecognizeMetadata__storage_, startTime),
        .flags = GPBFieldOptional,
        .dataType = GPBDataTypeMessage,
      },
      {
        .name = "lastUpdateTime",
        .dataTypeSpecific.className = GPBStringifySymbol(GPBTimestamp),
        .number = LongRunningRecognizeMetadata_FieldNumber_LastUpdateTime,
        .hasIndex = 2,
        .offset = (uint32_t)offsetof(LongRunningRecognizeMetadata__storage_, lastUpdateTime),
        .flags = GPBFieldOptional,
        .dataType = GPBDataTypeMessage,
      },
    };
    GPBDescriptor *localDescriptor =
        [GPBDescriptor allocDescriptorForClass:[LongRunningRecognizeMetadata class]
                                     rootClass:[CloudSpeechRoot class]
                                          file:CloudSpeechRoot_FileDescriptor()
                                        fields:fields
                                    fieldCount:(uint32_t)(sizeof(fields) / sizeof(GPBMessageFieldDescription))
                                   storageSize:sizeof(LongRunningRecognizeMetadata__storage_)
                                         flags:GPBDescriptorInitializationFlag_None];
    NSAssert(descriptor == nil, @"Startup recursed!");
    descriptor = localDescriptor;
  }
  return descriptor;
}

@end

#pragma mark - StreamingRecognizeResponse

@implementation StreamingRecognizeResponse

@dynamic hasError, error;
@dynamic resultsArray, resultsArray_Count;
@dynamic speechEventType;

typedef struct StreamingRecognizeResponse__storage_ {
  uint32_t _has_storage_[1];
  StreamingRecognizeResponse_SpeechEventType speechEventType;
  Status *error;
  NSMutableArray *resultsArray;
} StreamingRecognizeResponse__storage_;

// This method is threadsafe because it is initially called
// in +initialize for each subclass.
+ (GPBDescriptor *)descriptor {
  static GPBDescriptor *descriptor = nil;
  if (!descriptor) {
    static GPBMessageFieldDescription fields[] = {
      {
        .name = "error",
        .dataTypeSpecific.className = GPBStringifySymbol(Status),
        .number = StreamingRecognizeResponse_FieldNumber_Error,
        .hasIndex = 0,
        .offset = (uint32_t)offsetof(StreamingRecognizeResponse__storage_, error),
        .flags = GPBFieldOptional,
        .dataType = GPBDataTypeMessage,
      },
      {
        .name = "resultsArray",
        .dataTypeSpecific.className = GPBStringifySymbol(StreamingRecognitionResult),
        .number = StreamingRecognizeResponse_FieldNumber_ResultsArray,
        .hasIndex = GPBNoHasBit,
        .offset = (uint32_t)offsetof(StreamingRecognizeResponse__storage_, resultsArray),
        .flags = GPBFieldRepeated,
        .dataType = GPBDataTypeMessage,
      },
      {
        .name = "speechEventType",
        .dataTypeSpecific.enumDescFunc = StreamingRecognizeResponse_SpeechEventType_EnumDescriptor,
        .number = StreamingRecognizeResponse_FieldNumber_SpeechEventType,
        .hasIndex = 1,
        .offset = (uint32_t)offsetof(StreamingRecognizeResponse__storage_, speechEventType),
        .flags = (GPBFieldFlags)(GPBFieldOptional | GPBFieldHasEnumDescriptor),
        .dataType = GPBDataTypeEnum,
      },
    };
    GPBDescriptor *localDescriptor =
        [GPBDescriptor allocDescriptorForClass:[StreamingRecognizeResponse class]
                                     rootClass:[CloudSpeechRoot class]
                                          file:CloudSpeechRoot_FileDescriptor()
                                        fields:fields
                                    fieldCount:(uint32_t)(sizeof(fields) / sizeof(GPBMessageFieldDescription))
                                   storageSize:sizeof(StreamingRecognizeResponse__storage_)
                                         flags:GPBDescriptorInitializationFlag_None];
    NSAssert(descriptor == nil, @"Startup recursed!");
    descriptor = localDescriptor;
  }
  return descriptor;
}

@end

int32_t StreamingRecognizeResponse_SpeechEventType_RawValue(StreamingRecognizeResponse *message) {
  GPBDescriptor *descriptor = [StreamingRecognizeResponse descriptor];
  GPBFieldDescriptor *field = [descriptor fieldWithNumber:StreamingRecognizeResponse_FieldNumber_SpeechEventType];
  return GPBGetMessageInt32Field(message, field);
}

void SetStreamingRecognizeResponse_SpeechEventType_RawValue(StreamingRecognizeResponse *message, int32_t value) {
  GPBDescriptor *descriptor = [StreamingRecognizeResponse descriptor];
  GPBFieldDescriptor *field = [descriptor fieldWithNumber:StreamingRecognizeResponse_FieldNumber_SpeechEventType];
  GPBSetInt32IvarWithFieldInternal(message, field, value, descriptor.file.syntax);
}

#pragma mark - Enum StreamingRecognizeResponse_SpeechEventType

GPBEnumDescriptor *StreamingRecognizeResponse_SpeechEventType_EnumDescriptor(void) {
  static _Atomic(GPBEnumDescriptor*) descriptor = nil;
  if (!descriptor) {
    static const char *valueNames =
        "SpeechEventUnspecified\000EndOfSingleUttera"
        "nce\000";
    static const int32_t values[] = {
        StreamingRecognizeResponse_SpeechEventType_SpeechEventUnspecified,
        StreamingRecognizeResponse_SpeechEventType_EndOfSingleUtterance,
    };
    GPBEnumDescriptor *worker =
        [GPBEnumDescriptor allocDescriptorForName:GPBNSStringifySymbol(StreamingRecognizeResponse_SpeechEventType)
                                       valueNames:valueNames
                                           values:values
                                            count:(uint32_t)(sizeof(values) / sizeof(int32_t))
                                     enumVerifier:StreamingRecognizeResponse_SpeechEventType_IsValidValue];
    GPBEnumDescriptor *expected = nil;
    if (!atomic_compare_exchange_strong(&descriptor, &expected, worker)) {
      [worker release];
    }
  }
  return descriptor;
}

BOOL StreamingRecognizeResponse_SpeechEventType_IsValidValue(int32_t value__) {
  switch (value__) {
    case StreamingRecognizeResponse_SpeechEventType_SpeechEventUnspecified:
    case StreamingRecognizeResponse_SpeechEventType_EndOfSingleUtterance:
      return YES;
    default:
      return NO;
  }
}

#pragma mark - StreamingRecognitionResult

@implementation StreamingRecognitionResult

@dynamic alternativesArray, alternativesArray_Count;
@dynamic isFinal;
@dynamic stability;

typedef struct StreamingRecognitionResult__storage_ {
  uint32_t _has_storage_[1];
  float stability;
  NSMutableArray *alternativesArray;
} StreamingRecognitionResult__storage_;

// This method is threadsafe because it is initially called
// in +initialize for each subclass.
+ (GPBDescriptor *)descriptor {
  static GPBDescriptor *descriptor = nil;
  if (!descriptor) {
    static GPBMessageFieldDescription fields[] = {
      {
        .name = "alternativesArray",
        .dataTypeSpecific.className = GPBStringifySymbol(SpeechRecognitionAlternative),
        .number = StreamingRecognitionResult_FieldNumber_AlternativesArray,
        .hasIndex = GPBNoHasBit,
        .offset = (uint32_t)offsetof(StreamingRecognitionResult__storage_, alternativesArray),
        .flags = GPBFieldRepeated,
        .dataType = GPBDataTypeMessage,
      },
      {
        .name = "isFinal",
        .dataTypeSpecific.className = NULL,
        .number = StreamingRecognitionResult_FieldNumber_IsFinal,
        .hasIndex = 0,
        .offset = 1,  // Stored in _has_storage_ to save space.
        .flags = GPBFieldOptional,
        .dataType = GPBDataTypeBool,
      },
      {
        .name = "stability",
        .dataTypeSpecific.className = NULL,
        .number = StreamingRecognitionResult_FieldNumber_Stability,
        .hasIndex = 2,
        .offset = (uint32_t)offsetof(StreamingRecognitionResult__storage_, stability),
        .flags = GPBFieldOptional,
        .dataType = GPBDataTypeFloat,
      },
    };
    GPBDescriptor *localDescriptor =
        [GPBDescriptor allocDescriptorForClass:[StreamingRecognitionResult class]
                                     rootClass:[CloudSpeechRoot class]
                                          file:CloudSpeechRoot_FileDescriptor()
                                        fields:fields
                                    fieldCount:(uint32_t)(sizeof(fields) / sizeof(GPBMessageFieldDescription))
                                   storageSize:sizeof(StreamingRecognitionResult__storage_)
                                         flags:GPBDescriptorInitializationFlag_None];
    NSAssert(descriptor == nil, @"Startup recursed!");
    descriptor = localDescriptor;
  }
  return descriptor;
}

@end

#pragma mark - SpeechRecognitionResult

@implementation SpeechRecognitionResult

@dynamic alternativesArray, alternativesArray_Count;

typedef struct SpeechRecognitionResult__storage_ {
  uint32_t _has_storage_[1];
  NSMutableArray *alternativesArray;
} SpeechRecognitionResult__storage_;

// This method is threadsafe because it is initially called
// in +initialize for each subclass.
+ (GPBDescriptor *)descriptor {
  static GPBDescriptor *descriptor = nil;
  if (!descriptor) {
    static GPBMessageFieldDescription fields[] = {
      {
        .name = "alternativesArray",
        .dataTypeSpecific.className = GPBStringifySymbol(SpeechRecognitionAlternative),
        .number = SpeechRecognitionResult_FieldNumber_AlternativesArray,
        .hasIndex = GPBNoHasBit,
        .offset = (uint32_t)offsetof(SpeechRecognitionResult__storage_, alternativesArray),
        .flags = GPBFieldRepeated,
        .dataType = GPBDataTypeMessage,
      },
    };
    GPBDescriptor *localDescriptor =
        [GPBDescriptor allocDescriptorForClass:[SpeechRecognitionResult class]
                                     rootClass:[CloudSpeechRoot class]
                                          file:CloudSpeechRoot_FileDescriptor()
                                        fields:fields
                                    fieldCount:(uint32_t)(sizeof(fields) / sizeof(GPBMessageFieldDescription))
                                   storageSize:sizeof(SpeechRecognitionResult__storage_)
                                         flags:GPBDescriptorInitializationFlag_None];
    NSAssert(descriptor == nil, @"Startup recursed!");
    descriptor = localDescriptor;
  }
  return descriptor;
}

@end

#pragma mark - SpeechRecognitionAlternative

@implementation SpeechRecognitionAlternative

@dynamic transcript;
@dynamic confidence;
@dynamic wordsArray, wordsArray_Count;

typedef struct SpeechRecognitionAlternative__storage_ {
  uint32_t _has_storage_[1];
  float confidence;
  NSString *transcript;
  NSMutableArray *wordsArray;
} SpeechRecognitionAlternative__storage_;

// This method is threadsafe because it is initially called
// in +initialize for each subclass.
+ (GPBDescriptor *)descriptor {
  static GPBDescriptor *descriptor = nil;
  if (!descriptor) {
    static GPBMessageFieldDescription fields[] = {
      {
        .name = "transcript",
        .dataTypeSpecific.className = NULL,
        .number = SpeechRecognitionAlternative_FieldNumber_Transcript,
        .hasIndex = 0,
        .offset = (uint32_t)offsetof(SpeechRecognitionAlternative__storage_, transcript),
        .flags = GPBFieldOptional,
        .dataType = GPBDataTypeString,
      },
      {
        .name = "confidence",
        .dataTypeSpecific.className = NULL,
        .number = SpeechRecognitionAlternative_FieldNumber_Confidence,
        .hasIndex = 1,
        .offset = (uint32_t)offsetof(SpeechRecognitionAlternative__storage_, confidence),
        .flags = GPBFieldOptional,
        .dataType = GPBDataTypeFloat,
      },
      {
        .name = "wordsArray",
        .dataTypeSpecific.className = GPBStringifySymbol(WordInfo),
        .number = SpeechRecognitionAlternative_FieldNumber_WordsArray,
        .hasIndex = GPBNoHasBit,
        .offset = (uint32_t)offsetof(SpeechRecognitionAlternative__storage_, wordsArray),
        .flags = GPBFieldRepeated,
        .dataType = GPBDataTypeMessage,
      },
    };
    GPBDescriptor *localDescriptor =
        [GPBDescriptor allocDescriptorForClass:[SpeechRecognitionAlternative class]
                                     rootClass:[CloudSpeechRoot class]
                                          file:CloudSpeechRoot_FileDescriptor()
                                        fields:fields
                                    fieldCount:(uint32_t)(sizeof(fields) / sizeof(GPBMessageFieldDescription))
                                   storageSize:sizeof(SpeechRecognitionAlternative__storage_)
                                         flags:GPBDescriptorInitializationFlag_None];
    NSAssert(descriptor == nil, @"Startup recursed!");
    descriptor = localDescriptor;
  }
  return descriptor;
}

@end

#pragma mark - WordInfo

@implementation WordInfo

@dynamic hasStartTime, startTime;
@dynamic hasEndTime, endTime;
@dynamic word;

typedef struct WordInfo__storage_ {
  uint32_t _has_storage_[1];
  GPBTimestamp *startTime;
  GPBTimestamp *endTime;
  NSString *word;
} WordInfo__storage_;

// This method is threadsafe because it is initially called
// in +initialize for each subclass.
+ (GPBDescriptor *)descriptor {
  static GPBDescriptor *descriptor = nil;
  if (!descriptor) {
    static GPBMessageFieldDescription fields[] = {
      {
        .name = "startTime",
        .dataTypeSpecific.className = GPBStringifySymbol(GPBTimestamp),
        .number = WordInfo_FieldNumber_StartTime,
        .hasIndex = 0,
        .offset = (uint32_t)offsetof(WordInfo__storage_, startTime),
        .flags = GPBFieldOptional,
        .dataType = GPBDataTypeMessage,
      },
      {
        .name = "endTime",
        .dataTypeSpecific.className = GPBStringifySymbol(GPBTimestamp),
        .number = WordInfo_FieldNumber_EndTime,
        .hasIndex = 1,
        .offset = (uint32_t)offsetof(WordInfo__storage_, endTime),
        .flags = GPBFieldOptional,
        .dataType = GPBDataTypeMessage,
      },
      {
        .name = "word",
        .dataTypeSpecific.className = NULL,
        .number = WordInfo_FieldNumber_Word,
        .hasIndex = 2,
        .offset = (uint32_t)offsetof(WordInfo__storage_, word),
        .flags = GPBFieldOptional,
        .dataType = GPBDataTypeString,
      },
    };
    GPBDescriptor *localDescriptor =
        [GPBDescriptor allocDescriptorForClass:[WordInfo class]
                                     rootClass:[CloudSpeechRoot class]
                                          file:CloudSpeechRoot_FileDescriptor()
                                        fields:fields
                                    fieldCount:(uint32_t)(sizeof(fields) / sizeof(GPBMessageFieldDescription))
                                   storageSize:sizeof(WordInfo__storage_)
                                         flags:GPBDescriptorInitializationFlag_None];
    NSAssert(descriptor == nil, @"Startup recursed!");
    descriptor = localDescriptor;
  }
  return descriptor;
}

@end


#pragma clang diagnostic pop

// @@protoc_insertion_point(global_scope)
